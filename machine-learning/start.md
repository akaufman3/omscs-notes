# Supervised Learning

## Basics of Supervised Learning

•	Relies on human input to train a model
•	Supervised learning essentially works to create function approximation were it is given a number of pre defined input out put sets from a human that it uses to create a model that can predict or correctly label an never before-seen input with decent accuracy within an acceptable range
•	Parts of supervised learning: techniques, classification, regression, computational learning theory, Bayesian learning
•	There are two groups of algorithms used in supervised learning. Classification maps complex inputs to labels such as Tue or false or girl. Regression maps these inputs to often-numeric value that is continuous meaning can be mapped to fractions or decimals. Classification ends up dealing more with discrete values.
•	Errors can come from a variety of places including hardware, human element, malicious intent, unmodeled influences
•	You need to make sure known errors are present in the training data so that they ave factored in the model
•	However if too many errors in the training data then your model won’t reflect the real world accurately
•	There are various methods for reducing overfitting but one to combat errors in data is called cross-validation. Cross-validation takes some of the training data and creates a "fake" testing set. The goal here is to try to get the errors across both training data and cross- validation data are similar. 
•	The first step of breaking down a classification problem is making sure you have all the elements required. You need a good collection of instances that correctly represent the input data by which to train the overall model. You then need a classification abstraction which is a fundamental concept supporting the existence of a database system. This is more of a general idea or principle used to categorize things were the de thing characteristics are not based on concrete, tangible features but rather on Moro conceptual or tangible qualities. This concept can hopefully be represented by a well formed function. A target concept will also be needed which is the "answer" which allows us to classify based on our concept.We then have our hypotheses which are all the possible functions used to describe the concept. We will also need some input samples that ave paired with connect outputs so that we can gauge the accuracy of our outputs. We then want to identify a candidate which is a potential target concept. Lastly, we pull a testing set from our instances that the candidate concept has not yet seen in order to evaluate how close it is to the ideal target concept.
•	Decision trees are a representation of our features. An algorithm is used that the tree can apply to make a decision. Decision trees are a form of classification learning. Decision trees short start with questions that narrow down to decision making right away.
•	Defining questions can be approached from a mathematical perspective. We can say that a "good" starting question divides the data into half. This is a concept normally used in binary search.
•	A key issue with defining an algorithm however is that we want the algorithm to learn the tree not just use the tree to make decision.